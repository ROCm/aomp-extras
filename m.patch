commit 2d2314e0eff90aebb4b1c5c8c6f9f0a22f0f0516
Author: Gregory Rodgers <gregory.rodgers@amd.com>
Date:   Wed Aug 25 07:38:50 2021 -0500

    FIX openmpi_set_cu_mask for new runtime that uses env variable HSA_CU_MASK

diff --git a/utils/bin/openmpi_set_cu_mask b/utils/bin/openmpi_set_cu_mask
index dc3a63b..dfcbd17 100755
--- a/utils/bin/openmpi_set_cu_mask
+++ b/utils/bin/openmpi_set_cu_mask
@@ -1,14 +1,14 @@
 #!/bin/bash
 #
 #  openmpi_set_cu_mask: Script that reads OpenMPI environment variables and
-#                       builds ROCR_GLOBAL_CU_MASK accordingly then launches
+#                       builds HSA_CU_MASK accordingly then launches
 #                       the MPI process. This script demonstrates how to
 #                       distribute a GPU across multiple ranks of an MPI
 #                       job into mutually exclusive CU sets
 #
 #  Limitations:
 #  1 Only works with AOMP 13.0-2 or greater. This has a patched rocr/hsa
-#    runtime to support the ROCR_GLOBAL_CU_MASK env variable. Get AOMP 13.0-2
+#    runtime to support the HSA_CU_MASK env variable. Get AOMP 13.0-2
 #    here: https://github.com/ROCm-Developer-Tools/aomp/releases/tag/rel_13.0-2
 #  2 Only works with GPUs that have less than 64 CUs.
 #
@@ -20,7 +20,7 @@
 #
 #  Restrictions 3,4, & 5 are artifacts of this scripted implementation.
 #  Implementation by a workload manager process launch tool may be
-#  more flexible in setting ROCR_GLOBAL_CU_MASK.
+#  more flexible in setting HSA_CU_MASK.
 #
 #  Example Usage:
 #  mpirun -np 4 /usr/lib/aomp/bin/openmpi_set_cu_mask <MPI_APP_BINARY> <MPI_APP_ARGS>
@@ -92,8 +92,9 @@ for i in `seq 1 $_lz` ; do
 done
 _mask="0x$_mask"
 
-echo "ROCR_GLOBAL_CU_MASK:$_mask proc_num:$_local_proc_num"
-export ROCR_GLOBAL_CU_MASK=$_mask
+echo "HSA_CU_MASK:$_mask proc_num:$_local_proc_num"
+export ROCM_VISIBLE_DEVICES=0
+export HSA_CU_MASK=$ROCM_VISIBLE_DEVICES:$_mask
 
 # execute the application
 $*
